{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api_key = open(\"ticketmasterkey.txt\").read().strip()\n",
    "req_root = \"https://app.ticketmaster.com/discovery/v2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_req(req_type=\"events\", params={}):\n",
    "    params_str = \"\"\n",
    "    for k,v in params.items():\n",
    "        params_str += \"{}={}&\".format(k,v)\n",
    "    params_str += \"size=200&\"\n",
    "    params_str += \"sort=onSaleStartDate,asc&\"\n",
    "    params_str += \"apikey={}\".format(api_key)\n",
    "    return \"{}{}.json?{}\".format(req_root, req_type,params_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attrs(row):\n",
    "    DEFAULT_NUM_ATTRACTIONS = 5\n",
    "    DEFAULT_NUM_PRESALES = 15\n",
    "    \n",
    "    columns = ['numPresales','id','name','date','time','saleStart','saleEnd','numClassifications',\n",
    "        'segment','genre','subGenre','numPriceRanges','minPrice','maxPrice','numVenues',\n",
    "        'venueName','city','state','country']\n",
    "    \n",
    "    for num in range(DEFAULT_NUM_ATTRACTIONS):\n",
    "        columns.append(\"attraction_{}\".format(num))\n",
    "    \n",
    "    for num in range(DEFAULT_NUM_PRESALES):\n",
    "        columns.append(\"presale_{}\".format(num))\n",
    "        columns.append(\"presaleStart_{}\".format(num))\n",
    "        columns.append(\"presaleEnd_{}\".format(num))\n",
    "        \n",
    "    final = pd.DataFrame(index=[0], columns=columns)\n",
    "    \n",
    "    final.iloc[0][\"id\"] = row.get(\"id\")\n",
    "    final.iloc[0][\"name\"] = row.get(\"name\")\n",
    "    final.iloc[0][\"date\"] = row[\"dates\"][\"start\"].get(\"localDate\")\n",
    "    final.iloc[0][\"time\"] = row[\"dates\"][\"start\"].get(\"localTime\")\n",
    "    \n",
    "    # Attractions\n",
    "    if \"attractions\" in row[\"_embedded\"]:\n",
    "        for num, attraction in enumerate(row[\"_embedded\"][\"attractions\"]):\n",
    "            if num >= DEFAULT_NUM_ATTRACTIONS:\n",
    "                break\n",
    "            final.iloc[0][\"attraction_{}\".format(num)] = attraction.get(\"name\")\n",
    "            \n",
    "    # Sales\n",
    "    sales = row[\"sales\"]\n",
    "    final.iloc[0][\"saleStart\"] = sales[\"public\"].get(\"startDateTime\")\n",
    "    final.iloc[0][\"saleEnd\"] = sales[\"public\"].get(\"endDateTime\")\n",
    "    \n",
    "    if \"presales\" in sales:\n",
    "        final.iloc[0][\"numPresales\"] = len(sales[\"presales\"])\n",
    "        for num, presale in enumerate(sales[\"presales\"]):\n",
    "            final.iloc[0][\"presaleStart_{}\".format(num)] = presale.get(\"startDateTime\")\n",
    "            final.iloc[0][\"presaleEnd_{}\".format(num)] = presale.get(\"endDateTime\")\n",
    "            final.iloc[0][\"presale_{}\".format(num)] = presale.get(\"name\")\n",
    "\n",
    "    # Classifications\n",
    "    if \"classifications\" in row:\n",
    "        final.iloc[0][\"numClassifications\"] = len(row[\"classifications\"])\n",
    "        classifications = row[\"classifications\"][0]\n",
    "        if \"segment\" in classifications:\n",
    "            final.iloc[0][\"segment\"] = classifications[\"segment\"].get(\"name\")\n",
    "        if \"genre\" in classifications:\n",
    "            final.iloc[0][\"genre\"] = classifications[\"genre\"].get(\"name\")\n",
    "        if \"subGenre\" in classifications:\n",
    "            final.iloc[0][\"subGenre\"] = classifications[\"subGenre\"].get(\"name\")\n",
    "    \n",
    "    # Prices\n",
    "    if \"priceRange\" in row:\n",
    "        final.iloc[0][\"numPriceRanges\"] = len(row[\"priceRanges\"])\n",
    "        final.iloc[0][\"minPrice\"] = row[\"priceRanges\"][0].get(\"min\")\n",
    "        final.iloc[0][\"maxPrice\"] = row[\"priceRanges\"][0].get(\"max\")\n",
    "    \n",
    "    # Venues\n",
    "    final.iloc[0][\"numVenues\"] = len(row[\"_embedded\"][\"venues\"])\n",
    "    \n",
    "    venue = row[\"_embedded\"][\"venues\"][0]\n",
    "    final.iloc[0][\"venueName\"] = venue.get(\"name\")\n",
    "    if \"city\" in venue:\n",
    "        final.iloc[0][\"city\"] = venue[\"city\"].get(\"name\")\n",
    "    if \"state\" in venue:\n",
    "        final.iloc[0][\"state\"] = venue[\"state\"].get(\"stateCode\")\n",
    "    if \"country\" in venue:\n",
    "        final.iloc[0][\"country\"] = venue[\"country\"].get(\"countryCode\")\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_all(params = {}, filename=\"sales.csv\", num_pages=5, verbose=False):\n",
    "    \n",
    "    write_headers = False if os.path.exists(filename) else True    \n",
    "    if write_headers:\n",
    "        ids = set()\n",
    "    else:\n",
    "        ids = set(pd.DataFrame.from_csv(filename)[[\"id\"]].values.flat)\n",
    "    \n",
    "    with open(filename, 'a') as f:\n",
    "        for num in range(num_pages):\n",
    "            if verbose:\n",
    "                print(\"Page number: {} / {}\".format(num, num_pages),end=\"\\r\")\n",
    "            req = get_req(params={**params, **{\"page\": num}})\n",
    "            response = requests.get(req)\n",
    "            data = response.json()\n",
    "            if \"_embedded\" in data:\n",
    "                if \"events\" in data[\"_embedded\"]:\n",
    "                    rows = data[\"_embedded\"].get(\"events\")\n",
    "            \n",
    "                    for row in rows:\n",
    "                        attrs = get_attrs(row)\n",
    "                        ID = attrs[[\"id\"]].iloc[0][0]\n",
    "                        if ID not in ids:\n",
    "                            attrs.to_csv(f, header=write_headers)\n",
    "                            write_headers = False\n",
    "                            ids.add(ID)\n",
    "            if data[\"page\"][\"totalElements\"] < (num + 1) * 200:\n",
    "                break\n",
    "    if verbose:\n",
    "        print(\"Complete {}\\nSaved to {}\".format(params, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cities and States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = ['AL','AK','AZ','AR','CA','CO','CT','DE','FL','GA',\n",
    "          'HI','ID','IL','IN','IA','KS','KY','LA','ME','MD',\n",
    "          'MA','MI','MN','MS','MO','MT','NE','NV','NH','NJ',\n",
    "          'NM','NY','NC','ND','OH','OK','OR','PA','RI','SC',\n",
    "          'SD','TN','TX','UT','VT','VA','WA','WV','WI','WY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities = ['New York','Los Angeles','Chicago','Houston','Phoenix',\n",
    "          'Philadelphia','San Antonio','San Diego','Dallas','San Jose',\n",
    "          'Austin','Jacksonville','San Francisco','Columbus','Indianapolis',\n",
    "          'Fort Worth','Charlotte','Seattle','Denver','El Paso',\n",
    "          'Washington','Boston','Detroit','Nashville','Memphis',\n",
    "          'Portland','Oklahoma City','Las Vegas','Louisville','Baltimore',\n",
    "          'Milwaukee','Albuquerque','Tucson','Fresno','Sacramento','Mesa',\n",
    "          'Kansas City','Atlanta','Long Beach','Colorado Springs','Raleigh',\n",
    "          'Miami','Virginia Beach','Omaha','Oakland','Minneapolis','Tulsa',\n",
    "          'Arlington','New Orleans','Wichita','Cleveland','Tampa',\n",
    "          'Bakersfield','Aurora','Honolulu','Anaheim','Santa Ana',\n",
    "          'Corpus Christi','Riverside','Lexington','St. Louis','Stockton',\n",
    "          'Pittsburgh','Saint Paul','Cincinnati','Anchorage','Henderson',\n",
    "          'Greensboro','Plano','Newark','Lincoln','Toledo','Orlando','Chula Vista',\n",
    "          'Irvine','Fort Wayne','Jersey City','Durham','St. Petersburg',\n",
    "          'Laredo','Buffalo','Madison','Lubbock','Chandler','Scottsdale',\n",
    "          'Glendale','Reno','Norfolk','Winstonâ€“Salem','North Las Vegas',\n",
    "          'Irving','Chesapeake','Gilbert','Hialeah','Garland','Fremont',\n",
    "          'Baton Rouge','Richmond','Boise','San Bernardino','Spokane',\n",
    "          'Des Moines','Modesto','Birmingham','Tacoma','Fontana','Rochester',\n",
    "          'Oxnard','Moreno Valley','Fayetteville','Aurora','Glendale','Yonkers',\n",
    "          'Huntington Beach','Montgomery','Amarillo','Little Rock',\n",
    "          'Akron','Columbus','Augusta','Grand Rapids','Shreveport',\n",
    "          'Salt Lake City','Huntsville','Mobile','Tallahassee',\n",
    "          'Grand Prairie','Overland Park','Knoxville','Port St. Lucie',\n",
    "          'Worcester','Brownsville','Tempe','Santa Clarita','Newport News',\n",
    "          'Cape Coral','Providence','Fort Lauderdale','Chattanooga','Rancho Cucamonga',\n",
    "          'Oceanside','Santa Rosa','Garden Grove','Vancouver','Sioux Falls',\n",
    "          'Ontario','McKinney','Elk Grove','Jackson','Pembroke Pines',\n",
    "          'Salem','Springfield','Corona','Eugene','Fort Collins','Peoria',\n",
    "          'Frisco','Cary','Lancaster','Hayward','Palmdale','Salinas','Alexandria',\n",
    "          'Lakewood','Springfield','Pasadena','Sunnyvale','Macon','Pomona',\n",
    "          'Hollywood','Kansas City','Escondido','Clarksville','Joliet','Rockford',\n",
    "          'Torrance','Naperville','Paterson','Savannah','Bridgeport','Mesquite',\n",
    "          'Killeen','Syracuse','McAllen','Pasadena','Bellevue','Fullerton',\n",
    "          'Orange','Dayton','Miramar','Thornton','West Valley City','Olathe',\n",
    "          'Hampton','Warren','Midland','Waco','Charleston','Columbia','Denton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_sale_start_date_time = \"2017-10-10T00:00:00Z\"\n",
    "on_sale_start_date = \"2017-10-10\"\n",
    "\n",
    "for city in cities:\n",
    "    do_all(params={\"onsaleOnAfterStartDate\":on_sale_start_date,\"city\":city}, \n",
    "           filename=\"sales_20171009.csv\")\n",
    "    print(\"{}\".format(state), end=\" \")\n",
    "    sleep(np.random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fix_dates(\"sales_20171009.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dates(filename):\n",
    "    df = pd.DataFrame.from_csv(filename)\n",
    "    date_cols = [col for col in df.columns if 'start' in col.lower() \n",
    "                     or 'end' in col.lower()]\n",
    "    for date_col in date_cols:\n",
    "        df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"sales_20171009.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "presales = df[df.presaleStart_0 > dt.datetime.now()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-10-09'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# presales.to_csv(\"presales.csv\")\n",
    "on_sale_start_date = \"2017-10-10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_all(params={\"onsaleOnAfterStartDate\":on_sale_start_date,\"city\":'arlington'}, \n",
    "       filename=\"arlington_sales.csv\",num_pages=2)\n",
    "fix_dates(\"arlington_sales.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://app.ticketmaster.com/discovery/v2/events.json?onSaleStartDateTime=2017-10-10T00:00:00Z&city=arlington&size=200&sort=onSaleStartDate,asc&apikey=LAkX3xdKv160gdDWrsYSXxrWA8RXuUFa'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_req(params={\"onsaleOnAfterStartDate\":on_sale_start_date_time,\"city\":'arlington'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-10-10T00:00:00Z'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_sale_start_date_time\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
